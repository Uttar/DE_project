# Автоматизация и унификация мониторинга hadoop кластеров. 
Условие:
Есть 30+ кластеров Cloudera Hadoop, каждый месяц добавляются новые.
Zabbix в качестве системы монторинга jmx метрик, метрик, собираемых через api и пр.
Хранение исторических данных в родной базе Zabbix.
Большое количество разрозненных дашбордов в графане.

Проблемы:
1. Ручное заведение\изменение объектов мониторинга при добавление\изменении кластеров,
2. Ручное создание дашбордов в графане.
3. Ручная выгрузка селектами данных для аналитики (утилизация CPU\RAM очередями ярная, утилизация HDFS),

Решение:
1. Написание скрипта, который будет:
- работать с API cloudera manager service (CMS), формировать данные по имеющимся сервисам, нодам, где сервисы расположены.
- работать с API zabbix, добавлять\изменять объекты мониторинга, контролировать актуальность,
Скрипт должен:
- работать с git репозитерием, в котором хранятся инвентори данные кластеров (список, путь до SCM и пр.),
- быть готовым запускаться через Jenkins,
- возможность кастомизировать пороги триггеров для кластеров на основании заполненных конфигов в формате YAML.
2. Создание унфицированного дашборда типовых метрик, с вохможностью выбора кластера\сервиса\ноды.
3. Построенние ETL процесса над историческими данными:
- Нарисовать схему процесса 
- Источник - БД PostgreSQL Zabbix.
- Извлечение данных, написать скрип, который будет запускать селект, извлекающий только нужнные данные из таблиц. join таблиц history, items, groups. Выгружать в csv и складывать в слой сырых данных в hdfs.
- spark джоба, которая будет из csv преобразовывать данные в паркет файлы для дальнейшей аналитики.
